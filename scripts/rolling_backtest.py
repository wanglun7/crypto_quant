#!/usr/bin/env python3
"""
æ»šåŠ¨çª—å£å›æµ‹å·¥å…·

å®ç°æ—¶é—´åºåˆ—äº¤å‰éªŒè¯ï¼Œè¯„ä¼°æ¨¡å‹åœ¨ä¸åŒæ—¶é—´æ®µçš„ç¨³å®šæ€§ï¼š
1. å›ºå®šå¤§å°è®­ç»ƒçª—å£ï¼ˆå¦‚7å¤©ï¼‰
2. å›ºå®šé¢„æµ‹çª—å£ï¼ˆå¦‚1å¤©ï¼‰  
3. å‘å‰æ»šåŠ¨è¯„ä¼°
4. èšåˆå¤šä¸ªçª—å£çš„è¡¨ç°

ç›®æ ‡ï¼šæ£€æµ‹æ¨¡å‹æ˜¯å¦çœŸæ­£å…·å¤‡é¢„æµ‹èƒ½åŠ›ï¼Œè¿˜æ˜¯ä»…ä»…è¿‡æ‹Ÿåˆäº†ç‰¹å®šæ—¶é—´æ®µ
"""

import pandas as pd
import numpy as np
import torch
import torch.nn as nn
from datetime import datetime, timedelta
import structlog
import json
from pathlib import Path
import sys

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from crypto_quant.models.cnn_lstm import CNN_LSTM
from crypto_quant.utils.indicators import prepare_extended_data, add_extended_features
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score

logger = structlog.get_logger(__name__)


class RollingBacktester:
    """æ»šåŠ¨çª—å£å›æµ‹å™¨"""
    
    def __init__(self, train_days=7, test_days=1, step_days=1):
        """
        Args:
            train_days: è®­ç»ƒçª—å£å¤©æ•°
            test_days: æµ‹è¯•çª—å£å¤©æ•°  
            step_days: æ»šåŠ¨æ­¥é•¿å¤©æ•°
        """
        self.train_days = train_days
        self.test_days = test_days
        self.step_days = step_days
        self.results = []
        
    def create_time_windows(self, df):
        """åˆ›å»ºæ»šåŠ¨æ—¶é—´çª—å£"""
        
        # ç¡®ä¿æ•°æ®æŒ‰æ—¶é—´æ’åº
        df = df.sort_values('timestamp')
        
        # è®¡ç®—æ¯å¤©çš„åˆ†é’Ÿæ•°ï¼ˆå‡è®¾1åˆ†é’Ÿæ•°æ®ï¼‰
        minutes_per_day = 24 * 60
        train_size = self.train_days * minutes_per_day
        test_size = self.test_days * minutes_per_day
        step_size = self.step_days * minutes_per_day
        
        windows = []
        start_idx = 0
        
        while start_idx + train_size + test_size <= len(df):
            train_end = start_idx + train_size
            test_end = train_end + test_size
            
            train_data = df.iloc[start_idx:train_end].copy()
            test_data = df.iloc[train_end:test_end].copy()
            
            # è®°å½•æ—¶é—´çª—å£ä¿¡æ¯
            window_info = {
                'window_id': len(windows),
                'train_start': train_data['timestamp'].min(),
                'train_end': train_data['timestamp'].max(),
                'test_start': test_data['timestamp'].min(),
                'test_end': test_data['timestamp'].max(),
                'train_size': len(train_data),
                'test_size': len(test_data)
            }
            
            windows.append((train_data, test_data, window_info))
            start_idx += step_size
        
        logger.info(f"åˆ›å»ºæ»šåŠ¨çª—å£", total_windows=len(windows), 
                   train_days=self.train_days, test_days=self.test_days)
        
        return windows
    
    def train_model_for_window(self, train_data, test_data, sequence_length=60):
        """ä¸ºå•ä¸ªçª—å£è®­ç»ƒæ¨¡å‹"""
        
        try:
            # å‡†å¤‡è®­ç»ƒæ•°æ®
            X_train, y_train = prepare_extended_data(train_data, sequence_length)
            X_test, y_test = prepare_extended_data(test_data, sequence_length)
            
            if len(X_train) < 100:  # æœ€å°‘éœ€è¦100ä¸ªæ ·æœ¬
                logger.warning("è®­ç»ƒæ ·æœ¬ä¸è¶³", samples=len(X_train))
                return None, None, None
            
            # åˆ›å»ºæ¨¡å‹
            model = CNN_LSTM(
                n_features=26,  # æ‰©å±•ç‰¹å¾é›†
                sequence_length=sequence_length,
                cnn_filters=[32, 64, 128],
                lstm_hidden_size=64,
                lstm_num_layers=2,
                dropout_rate=0.3,
                fc_hidden_size=64
            )
            
            device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')
            model.to(device)
            
            # å¿«é€Ÿè®­ç»ƒï¼ˆå°‘é‡epochsï¼Œé’ˆå¯¹æ»šåŠ¨å›æµ‹ï¼‰
            optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
            criterion = nn.BCELoss()
            
            # è½¬æ¢ä¸ºPyTorchå¼ é‡
            X_train_tensor = torch.FloatTensor(X_train).to(device)
            y_train_tensor = torch.FloatTensor(y_train).unsqueeze(1).to(device)
            
            # è®­ç»ƒå¾ªç¯ï¼ˆå¿«é€Ÿç‰ˆæœ¬ï¼‰
            model.train()
            epochs = 10  # è¾ƒå°‘epochsä»¥èŠ‚çœæ—¶é—´
            
            for epoch in range(epochs):
                optimizer.zero_grad()
                outputs = model(X_train_tensor)
                loss = criterion(outputs, y_train_tensor)
                loss.backward()
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                optimizer.step()
            
            # é¢„æµ‹
            model.eval()
            X_test_tensor = torch.FloatTensor(X_test).to(device)
            
            with torch.no_grad():
                test_outputs = model(X_test_tensor).cpu().numpy().flatten()
            
            return model, test_outputs, y_test
            
        except Exception as e:
            logger.error("æ¨¡å‹è®­ç»ƒå¤±è´¥", error=str(e))
            return None, None, None
    
    def calculate_trading_metrics(self, probabilities, y_true, prices_data, threshold=0.3):
        """è®¡ç®—äº¤æ˜“æŒ‡æ ‡"""
        
        if probabilities is None or len(probabilities) == 0:
            return {}
        
        # ç”Ÿæˆä¿¡å·
        signals = (probabilities > threshold).astype(int)
        
        # è®¡ç®—åˆ†ç±»æŒ‡æ ‡
        accuracy = accuracy_score(y_true, signals)
        precision = precision_score(y_true, signals, zero_division=0)
        recall = recall_score(y_true, signals, zero_division=0)
        f1 = f1_score(y_true, signals, zero_division=0)
        
        try:
            auc = roc_auc_score(y_true, probabilities)
        except:
            auc = 0.5
        
        # è®¡ç®—äº¤æ˜“æ”¶ç›Šï¼ˆç®€åŒ–ç‰ˆï¼‰
        if len(prices_data) >= len(signals):
            price_returns = prices_data['close'].pct_change().iloc[1:len(signals)+1].values
            signal_returns = signals[:-1] * price_returns  # å‰ä¸€ä¸ªä¿¡å·å¯¹åº”ä¸‹ä¸€ä¸ªæ”¶ç›Š
            
            strategy_return = (1 + signal_returns).prod() - 1
            buy_hold_return = (prices_data['close'].iloc[-1] / prices_data['close'].iloc[0]) - 1
            
            # ç®€å•äº¤æ˜“æˆæœ¬
            trades = np.sum(np.diff(np.concatenate([[0], signals])) != 0)
            transaction_costs = trades * 0.0004  # 0.04% per trade
            net_return = strategy_return - transaction_costs
            
        else:
            strategy_return = 0
            buy_hold_return = 0
            net_return = 0
            trades = 0
        
        return {
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1_score': f1,
            'auc_score': auc,
            'strategy_return': strategy_return,
            'buy_hold_return': buy_hold_return,
            'net_return': net_return,
            'trades': trades,
            'prob_mean': probabilities.mean(),
            'prob_std': probabilities.std(),
            'signals_ratio': signals.mean()
        }
    
    def run_rolling_backtest(self, df):
        """è¿è¡Œå®Œæ•´çš„æ»šåŠ¨å›æµ‹"""
        
        print(f"ğŸš€ å¼€å§‹æ»šåŠ¨çª—å£å›æµ‹")
        print(f"è®­ç»ƒçª—å£: {self.train_days}å¤©, æµ‹è¯•çª—å£: {self.test_days}å¤©, æ­¥é•¿: {self.step_days}å¤©")
        print("="*70)
        
        # åˆ›å»ºæ—¶é—´çª—å£
        windows = self.create_time_windows(df)
        
        if len(windows) == 0:
            print("âŒ æ— æ³•åˆ›å»ºæ—¶é—´çª—å£ï¼Œæ•°æ®å¯èƒ½ä¸è¶³")
            return {}
        
        # å¤„ç†æ¯ä¸ªçª—å£
        for i, (train_data, test_data, window_info) in enumerate(windows):
            
            print(f"\nğŸ”„ çª—å£ {i+1}/{len(windows)}")
            print(f"   è®­ç»ƒ: {window_info['train_start'].date()} ~ {window_info['train_end'].date()}")
            print(f"   æµ‹è¯•: {window_info['test_start'].date()} ~ {window_info['test_end'].date()}")
            
            # è®­ç»ƒå¹¶é¢„æµ‹
            model, probabilities, y_true = self.train_model_for_window(train_data, test_data)
            
            if model is None:
                print(f"   âŒ çª—å£ {i+1} è®­ç»ƒå¤±è´¥")
                continue
            
            # è®¡ç®—æŒ‡æ ‡
            metrics = self.calculate_trading_metrics(probabilities, y_true, test_data)
            
            # æ·»åŠ çª—å£ä¿¡æ¯
            result = {**window_info, **metrics}
            self.results.append(result)
            
            # æ˜¾ç¤ºç»“æœ
            print(f"   ğŸ“Š å‡†ç¡®ç‡: {metrics['accuracy']:.3f}, F1: {metrics['f1_score']:.3f}")
            print(f"   ğŸ’° ç­–ç•¥æ”¶ç›Š: {metrics['net_return']:+.2%}, ä¹°å…¥æŒæœ‰: {metrics['buy_hold_return']:+.2%}")
            
            # å†…å­˜ç®¡ç†
            del model, probabilities
            torch.cuda.empty_cache() if torch.cuda.is_available() else None
        
        # èšåˆç»“æœ
        return self.aggregate_results()
    
    def aggregate_results(self):
        """èšåˆå¤šä¸ªçª—å£çš„ç»“æœ"""
        
        if not self.results:
            return {}
        
        # æ•°å€¼æŒ‡æ ‡çš„å¹³å‡å€¼
        numeric_metrics = ['accuracy', 'precision', 'recall', 'f1_score', 'auc_score', 
                          'strategy_return', 'buy_hold_return', 'net_return']
        
        aggregated = {}
        
        for metric in numeric_metrics:
            values = [r[metric] for r in self.results if metric in r and not np.isnan(r[metric])]
            if values:
                aggregated[f'{metric}_mean'] = np.mean(values)
                aggregated[f'{metric}_std'] = np.std(values)
                aggregated[f'{metric}_min'] = np.min(values)
                aggregated[f'{metric}_max'] = np.max(values)
        
        # èƒœç‡ç»Ÿè®¡
        strategy_wins = sum(1 for r in self.results if r.get('net_return', 0) > r.get('buy_hold_return', 0))
        aggregated['strategy_win_rate'] = strategy_wins / len(self.results)
        
        # ç´¯ç§¯æ”¶ç›Š
        cumulative_strategy = 1
        cumulative_buy_hold = 1
        
        for r in self.results:
            cumulative_strategy *= (1 + r.get('net_return', 0))
            cumulative_buy_hold *= (1 + r.get('buy_hold_return', 0))
        
        aggregated['cumulative_strategy_return'] = cumulative_strategy - 1
        aggregated['cumulative_buy_hold_return'] = cumulative_buy_hold - 1
        
        # æ€»ä½“ç»Ÿè®¡
        aggregated['total_windows'] = len(self.results)
        aggregated['successful_windows'] = len([r for r in self.results if 'accuracy' in r])
        
        return aggregated
    
    def generate_report(self, aggregated_results):
        """ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š"""
        
        print("\n" + "="*70)
        print("ğŸ“‹ æ»šåŠ¨çª—å£å›æµ‹æŠ¥å‘Š")
        print("="*70)
        
        if not aggregated_results:
            print("âŒ æ— æœ‰æ•ˆç»“æœ")
            return
        
        # åŸºæœ¬ç»Ÿè®¡
        print(f"æµ‹è¯•çª—å£æ•°é‡: {aggregated_results['total_windows']}")
        print(f"æˆåŠŸçª—å£æ•°é‡: {aggregated_results['successful_windows']}")
        print(f"æˆåŠŸç‡: {aggregated_results['successful_windows']/aggregated_results['total_windows']:.1%}")
        
        # æ¨¡å‹è¡¨ç°
        print(f"\nğŸ¤– æ¨¡å‹è¡¨ç° (å¹³å‡å€¼Â±æ ‡å‡†å·®):")
        print(f"   å‡†ç¡®ç‡: {aggregated_results.get('accuracy_mean', 0):.3f} Â± {aggregated_results.get('accuracy_std', 0):.3f}")
        print(f"   F1åˆ†æ•°: {aggregated_results.get('f1_score_mean', 0):.3f} Â± {aggregated_results.get('f1_score_std', 0):.3f}")
        print(f"   AUCåˆ†æ•°: {aggregated_results.get('auc_score_mean', 0):.3f} Â± {aggregated_results.get('auc_score_std', 0):.3f}")
        
        # äº¤æ˜“è¡¨ç°
        print(f"\nğŸ’° äº¤æ˜“è¡¨ç°:")
        print(f"   ç­–ç•¥èƒœç‡: {aggregated_results['strategy_win_rate']:.1%}")
        print(f"   ç´¯ç§¯ç­–ç•¥æ”¶ç›Š: {aggregated_results['cumulative_strategy_return']:+.2%}")
        print(f"   ç´¯ç§¯ä¹°å…¥æŒæœ‰: {aggregated_results['cumulative_buy_hold_return']:+.2%}")
        
        excess_return = aggregated_results['cumulative_strategy_return'] - aggregated_results['cumulative_buy_hold_return']
        print(f"   è¶…é¢æ”¶ç›Š: {excess_return:+.2%}")
        
        # ç¨³å®šæ€§åˆ†æ
        strategy_std = aggregated_results.get('net_return_std', 0)
        buy_hold_std = aggregated_results.get('buy_hold_return_std', 0)
        
        print(f"\nğŸ“Š ç¨³å®šæ€§åˆ†æ:")
        print(f"   ç­–ç•¥æ”¶ç›Šæ³¢åŠ¨: {strategy_std:.3f}")
        print(f"   ä¹°å…¥æŒæœ‰æ³¢åŠ¨: {buy_hold_std:.3f}")
        
        # ç»“è®º
        print(f"\nğŸ¯ ç»“è®º:")
        if aggregated_results['strategy_win_rate'] > 0.5:
            print(f"   âœ… ç­–ç•¥åœ¨{aggregated_results['strategy_win_rate']:.1%}çš„æ—¶é—´çª—å£ä¸­è¶…è¶Šä¹°å…¥æŒæœ‰")
        else:
            print(f"   âŒ ç­–ç•¥ä»…åœ¨{aggregated_results['strategy_win_rate']:.1%}çš„æ—¶é—´çª—å£ä¸­è¶…è¶Šä¹°å…¥æŒæœ‰")
            
        if abs(excess_return) < 0.01:  # 1%ä»¥å†…
            print(f"   âš–ï¸  ç­–ç•¥ä¸ä¹°å…¥æŒæœ‰è¡¨ç°æ¥è¿‘ï¼Œå¯èƒ½å­˜åœ¨è¿‡æ‹Ÿåˆ")
        elif excess_return > 0:
            print(f"   ğŸš€ ç­–ç•¥æ˜¾ç¤ºå‡ºæŒç»­çš„è¶…é¢æ”¶ç›Šèƒ½åŠ›")
        else:
            print(f"   ğŸ“‰ ç­–ç•¥æœªèƒ½æŒç»­è¶…è¶Šä¹°å…¥æŒæœ‰")
        
        print("="*70)


def main():
    """ä¸»å‡½æ•°"""
    
    # é…ç½®æ—¥å¿—
    structlog.configure(
        processors=[
            structlog.stdlib.filter_by_level,
            structlog.stdlib.add_log_level,
            structlog.processors.TimeStamper(fmt="iso"),
            structlog.processors.JSONRenderer()
        ],
        wrapper_class=structlog.stdlib.BoundLogger,
        logger_factory=structlog.stdlib.LoggerFactory(),
        cache_logger_on_first_use=True,
    )
    
    # åŠ è½½æ•°æ®
    try:
        df = pd.read_csv('data/BTC_USDT_1m_extended_30days.csv')
        df['timestamp'] = pd.to_datetime(df['timestamp'])
        
        print(f"ğŸ“Š æ•°æ®åŠ è½½å®Œæˆ: {len(df)} è¡Œ")
        print(f"æ—¶é—´èŒƒå›´: {df['timestamp'].min()} ~ {df['timestamp'].max()}")
        
    except FileNotFoundError:
        print("âŒ 30å¤©æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨")
        return False
    
    # åˆ›å»ºå›æµ‹å™¨
    backtester = RollingBacktester(
        train_days=7,   # 7å¤©è®­ç»ƒçª—å£
        test_days=1,    # 1å¤©æµ‹è¯•çª—å£
        step_days=1     # 1å¤©æ»šåŠ¨æ­¥é•¿
    )
    
    # è¿è¡Œå›æµ‹
    aggregated_results = backtester.run_rolling_backtest(df)
    
    # ç”ŸæˆæŠ¥å‘Š
    backtester.generate_report(aggregated_results)
    
    # ä¿å­˜è¯¦ç»†ç»“æœ
    results_data = {
        'aggregated_results': aggregated_results,
        'individual_windows': backtester.results,
        'backtest_params': {
            'train_days': backtester.train_days,
            'test_days': backtester.test_days,
            'step_days': backtester.step_days
        },
        'completed_at': datetime.now().isoformat()
    }
    
    with open('results/rolling_backtest_results.json', 'w') as f:
        json.dump(results_data, f, indent=2, default=str)
    
    print(f"\nğŸ’¾ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ° results/rolling_backtest_results.json")
    
    return True


if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)