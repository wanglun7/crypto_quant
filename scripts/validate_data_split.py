#!/usr/bin/env python3
"""
æ•°æ®åˆ†å‰²éªŒè¯å·¥å…· - ç¡®ä¿æ— æ•°æ®æ³„æ¼

æ£€æŸ¥é¡¹ç›®ï¼š
1. æ—¶é—´åºåˆ—ä¸¥æ ¼åˆ†å‰²ï¼šè®­ç»ƒ < éªŒè¯ < æµ‹è¯• 
2. æ— é‡å æ—¶é—´çª—å£
3. è¶³å¤Ÿçš„æ—¶é—´é—´éš”é˜²æ­¢å‰ç»æ€§åå·®
4. éªŒè¯ç‰¹å¾æ„é€ è¿‡ç¨‹ä¸­çš„æ•°æ®æ³„æ¼
"""

import pandas as pd
import numpy as np
from datetime import timedelta
import structlog
import sys
from pathlib import Path

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from scripts.train_optimized import TimeSeriesSplitter
from crypto_quant.utils.indicators import add_cnn_lstm_features

logger = structlog.get_logger(__name__)


class DataLeakageValidator:
    """æ•°æ®æ³„æ¼éªŒè¯å™¨"""
    
    def __init__(self):
        self.issues = []
    
    def validate_time_split(self, train_df, val_df, test_df):
        """éªŒè¯æ—¶é—´åˆ†å‰²æ˜¯å¦æ­£ç¡®"""
        
        print("ğŸ” éªŒè¯æ—¶é—´åºåˆ—åˆ†å‰²...")
        
        # 1. æ£€æŸ¥æ—¶é—´é¡ºåº
        train_end = train_df['timestamp'].max()
        val_start = val_df['timestamp'].min()
        val_end = val_df['timestamp'].max()
        test_start = test_df['timestamp'].min()
        
        print(f"è®­ç»ƒé›†æ—¶é—´: {train_df['timestamp'].min()} ~ {train_end}")
        print(f"éªŒè¯é›†æ—¶é—´: {val_start} ~ {val_end}")
        print(f"æµ‹è¯•é›†æ—¶é—´: {test_start} ~ {test_df['timestamp'].max()}")
        
        # 2. æ£€æŸ¥æ˜¯å¦æœ‰æ—¶é—´é‡å 
        if train_end >= val_start:
            issue = f"âŒ è®­ç»ƒé›†ä¸éªŒè¯é›†æ—¶é—´é‡å : {train_end} >= {val_start}"
            self.issues.append(issue)
            print(issue)
        else:
            print(f"âœ… è®­ç»ƒé›†ä¸éªŒè¯é›†æ— é‡å ")
        
        if val_end >= test_start:
            issue = f"âŒ éªŒè¯é›†ä¸æµ‹è¯•é›†æ—¶é—´é‡å : {val_end} >= {test_start}"
            self.issues.append(issue)
            print(issue)
        else:
            print(f"âœ… éªŒè¯é›†ä¸æµ‹è¯•é›†æ— é‡å ")
        
        # 3. æ£€æŸ¥æ—¶é—´é—´éš”
        train_val_gap = (val_start - train_end).total_seconds() / 60  # åˆ†é’Ÿ
        val_test_gap = (test_start - val_end).total_seconds() / 60    # åˆ†é’Ÿ
        
        print(f"è®­ç»ƒ-éªŒè¯é—´éš”: {train_val_gap}åˆ†é’Ÿ")
        print(f"éªŒè¯-æµ‹è¯•é—´éš”: {val_test_gap}åˆ†é’Ÿ")
        
        # å»ºè®®è‡³å°‘1åˆ†é’Ÿé—´éš”
        if train_val_gap < 1:
            issue = f"âš ï¸  è®­ç»ƒ-éªŒè¯é—´éš”è¿‡å°: {train_val_gap}åˆ†é’Ÿ"
            self.issues.append(issue)
            print(issue)
        
        if val_test_gap < 1:
            issue = f"âš ï¸  éªŒè¯-æµ‹è¯•é—´éš”è¿‡å°: {val_test_gap}åˆ†é’Ÿ"
            self.issues.append(issue)
            print(issue)
        
        return len(self.issues) == 0
    
    def validate_feature_leakage(self, df):
        """éªŒè¯ç‰¹å¾å·¥ç¨‹ä¸­æ˜¯å¦æœ‰æ•°æ®æ³„æ¼"""
        
        print("\nğŸ” éªŒè¯ç‰¹å¾å·¥ç¨‹æ•°æ®æ³„æ¼...")
        
        # æ£€æŸ¥æŠ€æœ¯æŒ‡æ ‡æ˜¯å¦ä½¿ç”¨äº†æœªæ¥æ•°æ®
        # é‡ç‚¹æ£€æŸ¥æ»šåŠ¨çª—å£è®¡ç®—
        
        original_len = len(df)
        df_with_features = add_cnn_lstm_features(df.copy())
        
        # æ£€æŸ¥æ˜¯å¦æœ‰NaNå€¼ï¼ˆå¯èƒ½è¡¨ç¤ºæ•°æ®ä¸è¶³ï¼‰
        nan_cols = df_with_features.columns[df_with_features.isnull().any()].tolist()
        
        if nan_cols:
            print(f"âš ï¸  å‘ç°åŒ…å«NaNçš„ç‰¹å¾åˆ—: {nan_cols}")
            print("è¿™å¯èƒ½æ˜¯ç”±äºæ»šåŠ¨çª—å£è®¡ç®—å¯¼è‡´çš„æ­£å¸¸ç°è±¡")
            
            # æ£€æŸ¥NaNçš„åˆ†å¸ƒ
            for col in nan_cols[:3]:  # åªæ£€æŸ¥å‰å‡ åˆ—
                nan_count = df_with_features[col].isnull().sum()
                print(f"  {col}: {nan_count} NaNå€¼ ({nan_count/len(df_with_features)*100:.1f}%)")
        else:
            print("âœ… æ‰€æœ‰ç‰¹å¾åˆ—éƒ½æ²¡æœ‰NaNå€¼")
        
        # æ£€æŸ¥ç‰¹å¾å€¼çš„åˆç†æ€§ï¼ˆç®€å•æ£€æŸ¥ï¼‰
        numeric_cols = df_with_features.select_dtypes(include=[np.number]).columns
        
        for col in ['RSI_14', 'Williams_R']:  # æ£€æŸ¥å‡ ä¸ªæœ‰æ˜ç¡®èŒƒå›´çš„æŒ‡æ ‡
            if col in numeric_cols:
                values = df_with_features[col].dropna()
                if len(values) > 0:
                    min_val, max_val = values.min(), values.max()
                    
                    if col == 'RSI_14':
                        if min_val < 0 or max_val > 100:
                            issue = f"âŒ {col} å€¼è¶…å‡ºæ­£å¸¸èŒƒå›´ [0,100]: [{min_val:.2f}, {max_val:.2f}]"
                            self.issues.append(issue)
                            print(issue)
                        else:
                            print(f"âœ… {col} å€¼åœ¨æ­£å¸¸èŒƒå›´å†…: [{min_val:.2f}, {max_val:.2f}]")
                    
                    elif col == 'Williams_R':
                        if min_val < -100 or max_val > 0:
                            issue = f"âŒ {col} å€¼è¶…å‡ºæ­£å¸¸èŒƒå›´ [-100,0]: [{min_val:.2f}, {max_val:.2f}]"
                            self.issues.append(issue)
                            print(issue)
                        else:
                            print(f"âœ… {col} å€¼åœ¨æ­£å¸¸èŒƒå›´å†…: [{min_val:.2f}, {max_val:.2f}]")
        
        return len(self.issues) == 0
    
    def validate_sequence_creation(self, df, sequence_length=60):
        """éªŒè¯åºåˆ—åˆ›å»ºè¿‡ç¨‹ä¸­çš„æ•°æ®æ³„æ¼"""
        
        print(f"\nğŸ” éªŒè¯åºåˆ—åˆ›å»ºè¿‡ç¨‹ (é•¿åº¦={sequence_length})...")
        
        # æ¨¡æ‹Ÿåºåˆ—åˆ›å»ºè¿‡ç¨‹
        n_samples = len(df) - sequence_length
        
        if n_samples <= 0:
            issue = f"âŒ æ•°æ®ä¸è¶³ä»¥åˆ›å»ºåºåˆ—: {len(df)} < {sequence_length}"
            self.issues.append(issue)
            print(issue)
            return False
        
        print(f"âœ… åŸå§‹æ•°æ®: {len(df)}è¡Œ")
        print(f"âœ… å¯åˆ›å»ºåºåˆ—: {n_samples}ä¸ª")
        print(f"âœ… æ•°æ®åˆ©ç”¨ç‡: {n_samples/len(df)*100:.1f}%")
        
        # æ£€æŸ¥åºåˆ—æ˜¯å¦æŒ‰æ—¶é—´é¡ºåº
        timestamps = df['timestamp'].values
        
        # éšæœºæ£€æŸ¥å‡ ä¸ªåºåˆ—
        for i in [0, n_samples//2, n_samples-1]:
            seq_times = timestamps[i:i+sequence_length]
            if not all(seq_times[j] <= seq_times[j+1] for j in range(len(seq_times)-1)):
                issue = f"âŒ åºåˆ— {i} æ—¶é—´é¡ºåºé”™è¯¯"
                self.issues.append(issue)
                print(issue)
            
        print(f"âœ… æ—¶é—´åºåˆ—é¡ºåºéªŒè¯é€šè¿‡")
        
        return True
    
    def generate_report(self):
        """ç”ŸæˆéªŒè¯æŠ¥å‘Š"""
        
        print("\n" + "="*60)
        print("ğŸ“‹ æ•°æ®æ³„æ¼éªŒè¯æŠ¥å‘Š")
        print("="*60)
        
        if len(self.issues) == 0:
            print("ğŸ‰ æ­å–œï¼æœªå‘ç°æ•°æ®æ³„æ¼é—®é¢˜")
            print("âœ… è®­ç»ƒæµç¨‹ç¬¦åˆæ—¶é—´åºåˆ—æœºå™¨å­¦ä¹ æœ€ä½³å®è·µ")
        else:
            print(f"âš ï¸  å‘ç° {len(self.issues)} ä¸ªæ½œåœ¨é—®é¢˜:")
            for i, issue in enumerate(self.issues, 1):
                print(f"{i}. {issue}")
        
        print("="*60)
        
        return len(self.issues) == 0


def main():
    """ä¸»éªŒè¯æµç¨‹"""
    
    print("ğŸš€ å¼€å§‹æ•°æ®åˆ†å‰²å’Œæ³„æ¼éªŒè¯")
    
    # 1. åŠ è½½æ•°æ®
    try:
        df = pd.read_csv('data/BTC_USDT_1m_extended_30days.csv')
        df['timestamp'] = pd.to_datetime(df['timestamp'])
        df = df.sort_values('timestamp')
        
        print(f"âœ… æ•°æ®åŠ è½½å®Œæˆ: {len(df)} è¡Œ")
        print(f"æ—¶é—´èŒƒå›´: {df['timestamp'].min()} ~ {df['timestamp'].max()}")
        
    except FileNotFoundError:
        print("âŒ 30å¤©æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨")
        return False
    
    # 2. æ‰§è¡Œæ—¶é—´åºåˆ—åˆ†å‰²
    splitter = TimeSeriesSplitter(train_ratio=0.6, val_ratio=0.2, test_ratio=0.2)
    train_df, val_df, test_df = splitter.split(df)
    
    # 3. åˆ›å»ºéªŒè¯å™¨å¹¶è¿è¡Œæ‰€æœ‰æ£€æŸ¥
    validator = DataLeakageValidator()
    
    # æ£€æŸ¥æ—¶é—´åˆ†å‰²
    validator.validate_time_split(train_df, val_df, test_df)
    
    # æ£€æŸ¥ç‰¹å¾å·¥ç¨‹
    validator.validate_feature_leakage(df)
    
    # æ£€æŸ¥åºåˆ—åˆ›å»º
    validator.validate_sequence_creation(df, sequence_length=60)
    
    # 4. ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
    is_valid = validator.generate_report()
    
    return is_valid


if __name__ == "__main__":
    # é…ç½®æ—¥å¿—
    structlog.configure(
        processors=[
            structlog.stdlib.filter_by_level,
            structlog.stdlib.add_log_level,
            structlog.processors.TimeStamper(fmt="iso"),
            structlog.processors.JSONRenderer()
        ],
        wrapper_class=structlog.stdlib.BoundLogger,
        logger_factory=structlog.stdlib.LoggerFactory(),
        cache_logger_on_first_use=True,
    )
    
    success = main()
    exit(0 if success else 1)